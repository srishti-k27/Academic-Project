library(readxl)
EM_ReturnsData <- read_excel("EM-ReturnsData.xlsx")
View(EM_ReturnsData)
# Load required libraries
install.packages("moments")  # For skewness and kurtosis
install.packages("psych")    # For descriptive statistics
install.packages("corrplot") # For correlation heatmap
install.packages("car")      # For VIF calculation
install.packages("lmtest")   # For diagnostic tests
install.packages("sandwich") # For robust standard errors
library(moments)
library(psych)
library(corrplot)
library(car)
library(lmtest)
library(sandwich)
# View first 6 rows
head(EM_ReturnsData)
# Check variable types
str(EM_ReturnsData)
# Summary statistics
summary(EM_ReturnsData)
# Check for missing values
colSums(is.na(EM_ReturnsData))
# Identify duplicates
sum(duplicated(EM_ReturnsData))
# Check if all columns are numeric
sapply(EM_ReturnsData, is.numeric)
# Boxplots to visualize outliers
boxplot(EM_ReturnsData$roe, main = "ROE Outliers")
boxplot(EM_ReturnsData$return, main = "Return Outliers")
# Outlier detection using IQR
Q1 <- quantile(EM_ReturnsData$roe, 0.25, na.rm = TRUE)
Q3 <- quantile(EM_ReturnsData$roe, 0.75, na.rm = TRUE)
IQR <- Q3 - Q1
lower_bound <- Q1 - 1.5 * IQR
upper_bound <- Q3 + 1.5 * IQR
outliers <- EM_ReturnsData$roe < lower_bound | EM_ReturnsData$roe > upper_bound
# Check for zero or negative values in `sal` and `netinc`
zero_or_negative_sal <- sum(EM_ReturnsData$sal <= 0)
zero_or_negative_netinc <- sum(EM_ReturnsData$netinc <= 0)
# Apply log transformation to `sal`
if (zero_or_negative_sal > 0) {
EM_ReturnsData$log_sal <- log(EM_ReturnsData$sal + 1)
} else {
EM_ReturnsData$log_sal <- log(EM_ReturnsData$sal)
}
# Apply log transformation to `netinc`
if (zero_or_negative_netinc > 0) {
EM_ReturnsData$log_netinc <- log(EM_ReturnsData$netinc + 1)
} else {
EM_ReturnsData$log_netinc <- log(EM_ReturnsData$netinc)
}
# Create squared term for `dkr`
EM_ReturnsData$dkr_sq <- EM_ReturnsData$dkr^2
# Calculate P/E ratio (P/E = Stock Price / EPS)
EM_ReturnsData$pe_ratio <- EM_ReturnsData$sp14 / EM_ReturnsData$eps
# Summary of original and transformed variables
summary(EM_ReturnsData[, c("sal", "netinc", "dkr", "sp14", "eps", "log_sal", "log_netinc", "dkr_sq", "pe_ratio")])
# Descriptive statistics
ivs <- c("roe", "roc", "dkr", "dkr_sq", "eps", "log_netinc", "log_sal", "pe_ratio")
# Function to calculate mode
get_mode <- function(x) {
ux <- unique(x)
ux[which.max(tabulate(match(x, ux)))]
}
# Compute descriptive statistics for IVs
desc_stats <- sapply(EM_ReturnsData[, ivs], function(x) {
c(
Mean = mean(x, na.rm = TRUE),
Median = median(x, na.rm = TRUE),
Mode = get_mode(x),
Variance = var(x, na.rm = TRUE),
SD = sd(x, na.rm = TRUE),
Min = min(x, na.rm = TRUE),
Max = max(x, na.rm = TRUE),
Range = max(x, na.rm = TRUE) - min(x, na.rm = TRUE)
)
})
# Transpose for better readability
desc_stats <- t(desc_stats)
print("Descriptive Statistics:")
print(desc_stats)
# Compute skewness and kurtosis
skew_kurt <- sapply(EM_ReturnsData[, ivs], function(x) {
c(
Skewness = skewness(x, na.rm = TRUE),
Kurtosis = kurtosis(x, na.rm = TRUE)
)
})
# Transpose for better readability
skew_kurt <- t(skew_kurt)
print("Skewness and Kurtosis:")
print(skew_kurt)
# Compute quantiles
quantiles <- sapply(EM_ReturnsData[, ivs], function(x) {
quantile(x, probs = c(0, 0.25, 0.5, 0.75, 1), na.rm = TRUE)
})
# Transpose for better readability
quantiles <- t(quantiles)
print("Quantiles:")
print(quantiles)
# Compute correlation matrix
cor_matrix <- cor(EM_ReturnsData[, ivs], use = "complete.obs")
print("Correlation Matrix:")
print(cor_matrix)
# Create correlation heatmap
corrplot(cor_matrix,
method = "color", type = "upper",
tl.col = "black", tl.srt = 45,
addCoef.col = "black", number.cex = 0.7,
main = "Correlation Heatmap of Independent Variables")
# Run the regression model
model <- lm(return ~ roe + dkr + dkr_sq + eps + log_netinc + log_sal + pe_ratio, data = EM_ReturnsData)
summary(model)
# Calculate Variance Inflation Factor (VIF)
vif_values <- vif(model)
print(vif_values)
# Create a bar plot for VIF values
barplot(vif_values, main = "VIF Values", horiz = TRUE, col = "steelblue")
abline(v = 5, lwd = 3, lty = 2, col = "red")
# Check Zero Conditional Mean (ZCM) assumption
residuals_model <- residuals(model)
# Regress residuals on independent variables
zcm_test <- lm(residuals_model ~ roe + dkr + dkr_sq + eps + log_netinc + log_sal + pe_ratio, data = EM_ReturnsData)
summary(zcm_test)
# Test if the mean of residuals is zero
t_test_residuals <- t.test(residuals_model, mu = 0)
print(t_test_residuals)
# Perform Ramsey RESET test
reset_test <- resettest(model, power = 2, type = "fitted")
print(reset_test)
# Breusch-Pagan test for heteroskedasticity
bptest(model)
# Visual Check: Residuals vs Fitted Plot
plot(fitted(model), residuals(model),
main = "Residuals vs. Fitted",
xlab = "Fitted Values", ylab = "Residuals",
pch = 20, col = "blue")
abline(h = 0, col = "red", lwd = 2)
# Test for normality of residuals
hist(residuals(model), breaks = 30, col = "lightblue", main = "Histogram of Residuals", xlab = "Residuals", probability = TRUE)
lines(density(residuals(model)), col = "red", lwd = 2)
# Shapiro-Wilk test for normality
shapiro.test(residuals(model))
#normality assumption is violated
> #some of these variables have high skewness and kurtosis as observed before
#normality assumption is violated
#some of these variables have high skewness and kurtosis as observed before
# List of independent variables
vars <- c("roe", "roc", "dkr", "dkr_sq", "eps", "log_netinc", "log_sal", "pe_ratio")
# Set up a 3x3 plotting grid
par(mfrow = c(3, 3), mar = c(3, 3, 2, 1))  # Adjust margins if needed
# Loop through variables and plot histograms
for (var in vars) {
hist(EM_ReturnsData[[var]],
main = paste("Histogram of", var),
col = "steelblue",
border = "black",
xlab = var,
breaks = 20)
}
#roc was not needed
# Load necessary libraries
library(car)       # For VIF calculation
library(lmtest)    # For diagnostic tests
library(ggplot2)   # For visualization
library(moments)   # For skewness and kurtosis
# Define independent variables
ivs <- c("roe", "dkr", "dkr_sq", "eps", "log_netinc", "log_sal", "pe_ratio")
# Compute correlation matrix
cor_matrix <- cor(EM_ReturnsData[, ivs], use = "complete.obs")
# Print correlation matrix with formatting
cat("\nCorrelation Matrix:\n")
print(format(cor_matrix, digits = 4, justify = "left"))
# Fit the linear model
model <- lm(return ~ roe + dkr + dkr_sq + eps + log_netinc + log_sal + pe_ratio, data = EM_ReturnsData)
# Extract residuals
residuals_model <- residuals(model)
# Compute Skewness and Kurtosis
residual_skewness <- skewness(residuals_model, na.rm = TRUE)
residual_kurtosis <- kurtosis(residuals_model, na.rm = TRUE)
# Print Skewness and Kurtosis
cat("\nSkewness and Kurtosis of Residuals:\n")
print(data.frame(Statistic = c("Skewness", "Kurtosis"), Value = c(residual_skewness, residual_kurtosis)))
# Histogram of residuals
hist(residuals_model, main = "Histogram of Residuals", col = "lightblue", breaks = 20)
# Compute Cookâ€™s Distance
cooksd <- cooks.distance(model)
# Visualize influential points
plot(cooksd, type = "h", main = "Cook's Distance", col = "blue")
abline(h = 4/length(cooksd), col = "red")  # Threshold line
# Identify potential outliers
outliers <- which(cooksd > 4/length(cooksd))
cat("\nIdentified Outliers:\n")
print(outliers)
# Remove outliers from the dataset
EM_ReturnsData_cleaned <- EM_ReturnsData[-outliers, ]
# Refit the model without outliers
model_cleaned <- lm(return ~ roe + dkr + dkr_sq + eps + log_netinc + log_sal + pe_ratio,
data = EM_ReturnsData_cleaned)
# Check normality with Shapiro-Wilk test
shapiro_test <- shapiro.test(residuals(model_cleaned))
cat("\nShapiro-Wilk Normality Test:\n")
print(shapiro_test)
# Histogram of residuals after cleaning
hist(residuals(model_cleaned), main = "Histogram of Residuals (Cleaned)", xlab = "Residuals", col = "lightblue", breaks = 30)
# Q-Q Plot
qqnorm(residuals(model_cleaned))
qqline(residuals(model_cleaned), col = "red")
# Residuals vs Fitted plot
plot(fitted(model_cleaned), residuals(model_cleaned),
main = "Residuals vs Fitted",
xlab = "Fitted Values", ylab = "Residuals",
col = "blue", pch = 20)
abline(h = 0, col = "red")
# Breusch-Pagan Test for Heteroskedasticity
bptest_result <- bptest(model_cleaned)
cat("\nBreusch-Pagan Test:\n")
print(bptest_result)
# Ramsey RESET test for specification errors
reset_test <- resettest(model_cleaned, power = 2, type = "fitted")
cat("\nRamsey RESET Test:\n")
print(reset_test)
# Compute correlation between residuals and predictors
residuals_cleaned <- residuals(model_cleaned)
predictors <- model.matrix(model_cleaned)[, -1]
cor_results <- apply(predictors, 2, function(x) cor(x, residuals_cleaned))
# Print correlation results
cat("\nCorrelation between Residuals and Predictors:\n")
print(cor_results)
# Compute Variance Inflation Factor (VIF)
vif_values <- vif(model_cleaned)
cat("\nVariance Inflation Factor (VIF):\n")
print(vif_values)
# Create a bar plot for VIF values using ggplot2
vif_df <- data.frame(Variable = names(vif_values), VIF = vif_values)
ggplot(vif_df, aes(x = reorder(Variable, VIF), y = VIF)) +
geom_bar(stat = "identity", fill = "skyblue") +
geom_hline(yintercept = 10, color = "red", linetype = "dashed", linewidth = 1) +
labs(title = "Variance Inflation Factor (VIF)", x = "Predictor Variables", y = "VIF Value") +
theme_minimal() +
coord_flip()  # Flip for better readability
# Create a simple horizontal bar plot for VIF
barplot(vif_values, main = "VIF Values", horiz = TRUE,
col = "steelblue", xlab = "VIF")
abline(v = 10, lwd = 3, lty = 2, col = "red")  # Threshold line
summary(model_cleaned)
#end
